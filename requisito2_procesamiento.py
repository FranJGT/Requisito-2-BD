#!/usr/bin/env python3
"""
Requisito 2: Preprocesamiento del Corpus
Vectorizaci√≥n e Inserci√≥n en MongoDB

Este script procesa discursos hist√≥ricos, genera embeddings sem√°nticos
y los almacena en MongoDB configurado con Replica Set.
"""

import os
import sys
import hashlib
import json
import time
from datetime import datetime
from pathlib import Path
import logging
from typing import Dict, List, Tuple, Optional

import numpy as np
from sentence_transformers import SentenceTransformer
from pymongo import MongoClient, WriteConcern, errors
from pymongo.errors import ConnectionFailure, ServerSelectionTimeoutError
from tqdm import tqdm

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('procesamiento_requisito2.log', encoding='utf-8'),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)


class CorpusProcessor:
    """
    Procesador de corpus de discursos para vectorizaci√≥n e inserci√≥n en MongoDB.
    Dise√±ado para trabajar con el Replica Set configurado en el Requisito 1.
    """
    
    def __init__(self, corpus_path: str):
        """
        Inicializa el procesador con la ruta del corpus.
        
        Args:
            corpus_path: Ruta a la carpeta con los archivos .txt
        """
        self.corpus_path = Path(corpus_path)
        self.client = None
        self.db = None
        self.collection = None
        self.model = None
        
        self.stats = {
            'procesados': 0,
            'errores': 0,
            'duplicados': 0,
            'tiempo_inicio': datetime.now(),
            'archivos_error': []
        }
        
        self.MONGO_PORTS = [3001, 3002, 3003]
        self.REPLICA_SET = "rs"
        self.DATABASE_NAME = "Pol√≠tica"  
        self.COLLECTION_NAME = "Discursos"
        
        self._initialize_components()
    
    def _initialize_components(self):
        """Inicializa modelo de embeddings y conexi√≥n a MongoDB"""
        logger.info("ü§ñ Cargando modelo de embeddings...")
        try:
            self.model = SentenceTransformer('all-MiniLM-L6-v2')
            logger.info("‚úÖ Modelo cargado exitosamente")
            
            logger.info(f"   - Dimensi√≥n de embeddings: {self.model.get_sentence_embedding_dimension()}")
            
        except Exception as e:
            logger.error(f"‚ùå Error cargando modelo: {e}")
            raise
        
        self._connect_to_mongodb()
    
    def _connect_to_mongodb(self):
        """
        Establece conexi√≥n con MongoDB Replica Set.
        Intenta m√∫ltiples estrategias de conexi√≥n.
        """
        logger.info("üîå Conectando a MongoDB Replica Set...")
        
        for port in self.MONGO_PORTS:
            try:
                logger.info(f"   Intentando puerto {port}...")
                self.client = MongoClient(
                    f'mongodb://localhost:{port}',
                    serverSelectionTimeoutMS=5000,
                    directConnection=True
                )
                self.client.admin.command('ping')
                logger.info(f"‚úÖ Conexi√≥n exitosa a MongoDB (puerto {port})")
                break
                
            except (ConnectionFailure, ServerSelectionTimeoutError) as e:
                logger.warning(f"   ‚ö†Ô∏è  No se pudo conectar al puerto {port}")
                continue
        
        if not self.client:
            try:
                logger.info("   Intentando conexi√≥n a Replica Set completo...")
                replica_set_uri = f"mongodb://localhost:{self.MONGO_PORTS[0]},localhost:{self.MONGO_PORTS[1]},localhost:{self.MONGO_PORTS[2]}/?replicaSet={self.REPLICA_SET}"
                
                self.client = MongoClient(
                    replica_set_uri,
                    serverSelectionTimeoutMS=10000
                )
                self.client.admin.command('ping')
                logger.info("‚úÖ Conexi√≥n exitosa a MongoDB Replica Set")
                
            except Exception as e:
                logger.error(f"‚ùå No se pudo conectar a MongoDB: {e}")
                raise ConnectionError("No se pudo establecer conexi√≥n con MongoDB. Verifica que el Requisito 1 est√© funcionando.")
            
        self.db = self.client[self.DATABASE_NAME]
        self.collection = self.db[self.COLLECTION_NAME]
        
        self._show_connection_info()
    
    def _show_connection_info(self):
        """Muestra informaci√≥n sobre la conexi√≥n establecida"""
        try:
            server_info = self.client.server_info()
            logger.info(f"üìä Informaci√≥n del servidor MongoDB:")
            logger.info(f"   - Versi√≥n: {server_info.get('version', 'desconocida')}")
            
            if self.client.admin.command('isMaster').get('setName'):
                status = self.client.admin.command('replSetGetStatus')
                logger.info(f"   - Replica Set: {status['set']}")
                logger.info(f"   - Miembros activos: {len(status['members'])}")
                
                for member in status['members']:
                    state = member['stateStr']
                    name = member['name']
                    logger.info(f"     ‚Ä¢ {name}: {state}")
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è  No se pudo obtener informaci√≥n completa del servidor: {e}")
    
    def generate_sha256(self, text: str) -> str:
        """
        Genera hash SHA-256 del texto.
        
        Args:
            text: Texto a hashear
            
        Returns:
            Hash hexadecimal de 64 caracteres
        """
        return hashlib.sha256(text.encode('utf-8')).hexdigest()
    
    def generate_embedding(self, text: str) -> List[float]:
        """
        Genera embedding del texto usando sentence-transformers.
        
        Args:
            text: Texto a vectorizar
            
        Returns:
            Lista de floats representando el embedding
        """
        try:
            embedding = self.model.encode(text, show_progress_bar=False)
            
            return embedding.tolist()
            
        except Exception as e:
            logger.error(f"Error generando embedding: {e}")
            raise
    
    def process_file(self, filepath: Path) -> Optional[Dict]:
        """
        Procesa un archivo individual y retorna el documento MongoDB.
        
        Args:
            filepath: Ruta al archivo .txt
            
        Returns:
            Diccionario con la estructura del documento o None si hay error
        """
        try:
            texto = None
            encodings = ['utf-8', 'latin-1', 'iso-8859-1', 'cp1252']
            
            for encoding in encodings:
                try:
                    with open(filepath, 'r', encoding=encoding) as f:
                        texto = f.read().strip()
                    break
                except UnicodeDecodeError:
                    continue
            
            if texto is None:
                raise ValueError(f"No se pudo leer el archivo con ning√∫n encoding")
            
            if not texto:
                raise ValueError("Archivo vac√≠o")
            
            doc_id = self.generate_sha256(texto)
            
            embedding = self.generate_embedding(texto)
            
            documento = {
                "_id": doc_id,
                "texto": texto,
                "embedding": embedding
            }
            
            return documento
            
        except Exception as e:
            logger.error(f"Error procesando {filepath.name}: {str(e)}")
            self.stats['archivos_error'].append({
                'archivo': filepath.name,
                'error': str(e)
            })
            return None
    
    def process_corpus(self):
        """
        Procesa todos los archivos del corpus.
        M√©todo principal que coordina todo el procesamiento.
        """
        logger.info("\n" + "="*60)
        logger.info("üöÄ INICIANDO PROCESAMIENTO DEL CORPUS")
        logger.info("="*60)
        
        txt_files = list(self.corpus_path.glob('*.txt'))
        total_files = len(txt_files)
        
        if total_files == 0:
            logger.error(f"‚ùå No se encontraron archivos .txt en {self.corpus_path}")
            return
        
        logger.info(f"üìÅ Encontrados {total_files} archivos para procesar")
        logger.info(f"üìç Carpeta: {self.corpus_path.absolute()}")
        
        with tqdm(total=total_files, desc="Procesando discursos", unit="archivo") as pbar:
            for idx, filepath in enumerate(txt_files):
                try:
                    documento = self.process_file(filepath)
                    
                    if documento is None:
                        self.stats['errores'] += 1
                        pbar.update(1)
                        continue
                    
                    result = self.collection.with_options(write_concern=WriteConcern(w="majority", wtimeout=5000)).insert_one(documento)
                    
                    self.stats['procesados'] += 1

                    pbar.set_postfix({
                        'Procesados': self.stats['procesados'],
                        'Errores': self.stats['errores'],
                        'Duplicados': self.stats['duplicados']
                    })
                    
                except errors.DuplicateKeyError:
                    logger.warning(f"‚ö†Ô∏è  Documento duplicado: {filepath.name}")
                    self.stats['duplicados'] += 1
                    
                except Exception as e:
                    logger.error(f"‚ùå Error con {filepath.name}: {str(e)}")
                    self.stats['errores'] += 1
                    self.stats['archivos_error'].append({
                        'archivo': filepath.name,
                        'error': str(e)
                    })
                
                pbar.update(1)
                
                if (idx + 1) % 50 == 0:
                    time.sleep(0.1)
        
        self._print_summary()
    
    def _print_summary(self):
        """Imprime resumen detallado del procesamiento"""
        duracion = (datetime.now() - self.stats['tiempo_inicio']).total_seconds()
        
        print("\n" + "="*60)
        print("üìä RESUMEN DEL PROCESAMIENTO")
        print("="*60)
        print(f"‚úÖ Documentos procesados exitosamente: {self.stats['procesados']}")
        print(f"‚ö†Ô∏è  Documentos duplicados omitidos: {self.stats['duplicados']}")
        print(f"‚ùå Errores durante el procesamiento: {self.stats['errores']}")
        print(f"‚è±Ô∏è  Tiempo total de procesamiento: {duracion:.2f} segundos")
        print(f"‚ö° Velocidad promedio: {self.stats['procesados']/duracion:.2f} docs/segundo")
        print(f"üì¶ Total documentos en la colecci√≥n: {self.collection.count_documents({})}")
        print("="*60)
        
        if self.stats['archivos_error']:
            print("\n‚ö†Ô∏è  ARCHIVOS CON ERRORES:")
            print("-"*60)
            for error_info in self.stats['archivos_error'][:5]: 
                print(f"   ‚Ä¢ {error_info['archivo']}: {error_info['error']}")
            if len(self.stats['archivos_error']) > 5:
                print(f"   ... y {len(self.stats['archivos_error']) - 5} errores m√°s")
    
    def validate_collection(self):
        """
        Valida la integridad de la colecci√≥n despu√©s del procesamiento.
        Verifica estructura, consistencia y replicaci√≥n.
        """
        logger.info("\n" + "="*60)
        logger.info("üîç VALIDACI√ìN DE LA COLECCI√ìN")
        logger.info("="*60)
        
        total_docs = self.collection.count_documents({})
        logger.info(f"üìä Total de documentos en la colecci√≥n: {total_docs}")
        
        if total_docs == 0:
            logger.warning("‚ö†Ô∏è  La colecci√≥n est√° vac√≠a")
            return False

        sample = self.collection.find_one()
        if sample:
            logger.info("\n‚úÖ Estructura del documento de muestra:")
            logger.info(f"   - ID (SHA-256): {sample['_id'][:32]}...")
            logger.info(f"   - Longitud del texto: {len(sample['texto'])} caracteres")
            logger.info(f"   - Dimensi√≥n del embedding: {len(sample['embedding'])}")
            logger.info(f"   - Primeras palabras: {' '.join(sample['texto'].split()[:10])}...")
        
        logger.info("\nüìê Verificando consistencia de embeddings...")
        pipeline = [
            {"$project": {
                "embedding_size": {"$size": "$embedding"}
            }},
            {"$group": {
                "_id": "$embedding_size",
                "count": {"$sum": 1}
            }}
        ]
        
        sizes = list(self.collection.aggregate(pipeline))
        
        if len(sizes) == 1 and sizes[0]['_id'] == 384:
            logger.info(f"‚úÖ Todos los {sizes[0]['count']} documentos tienen embeddings de 384 dimensiones")
        else:
            logger.warning("‚ö†Ô∏è  Inconsistencia en las dimensiones de embeddings:")
            for size in sizes:
                logger.warning(f"   - {size['count']} documentos con {size['_id']} dimensiones")
        
        logger.info("\nüîé Verificando campos requeridos...")
        docs_sin_texto = self.collection.count_documents({"texto": {"$exists": False}})
        docs_sin_embedding = self.collection.count_documents({"embedding": {"$exists": False}})
        
        if docs_sin_texto == 0 and docs_sin_embedding == 0:
            logger.info("‚úÖ Todos los documentos tienen los campos requeridos")
        else:
            if docs_sin_texto > 0:
                logger.warning(f"‚ö†Ô∏è  {docs_sin_texto} documentos sin campo 'texto'")
            if docs_sin_embedding > 0:
                logger.warning(f"‚ö†Ô∏è  {docs_sin_embedding} documentos sin campo 'embedding'")
        
        logger.info("\nüîß Verificando estado del Replica Set...")
        try:
            status = self.client.admin.command('replSetGetStatus')
            logger.info(f"‚úÖ Replica Set '{status['set']}' activo")
            logger.info(f"   - Miembros: {len(status['members'])}")
            
            primary_count = sum(1 for m in status['members'] if m['stateStr'] == 'PRIMARY')
            if primary_count == 1:
                logger.info("   - ‚úÖ Primario activo")
            else:
                logger.warning(f"   - ‚ö†Ô∏è  {primary_count} primarios detectados (deber√≠a ser 1)")
                
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è  No se pudo verificar el estado del Replica Set: {e}")
        
        logger.info("="*60)
        
        return True
    
    def create_indexes(self):
        """
        Crea √≠ndices adicionales para optimizar las b√∫squedas futuras.
        """
        logger.info("\nüìá Creando √≠ndices para optimizaci√≥n...")
        
        try:
            self.collection.create_index([("texto", "text")], name="text_index")
            logger.info("‚úÖ √çndice de texto creado")
            
            self.collection.create_index("embedding", name="embedding_index", sparse=True)
            logger.info("‚úÖ √çndice de embedding creado")
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è  Error creando √≠ndices: {e}")
    
    def close(self):
        """Cierra la conexi√≥n a MongoDB"""
        if self.client:
            self.client.close()
            logger.info("üîå Conexi√≥n a MongoDB cerrada")


def main():
    """Funci√≥n principal del script"""
    print("\n" + "üåü"*30)
    print("LABORATORIO 2 - REQUISITO 2")
    print("Preprocesamiento y Vectorizaci√≥n del Corpus")
    print("üåü"*30 + "\n")
    
    CORPUS_PATH = "./DiscursosOriginales"
    
    if not os.path.exists(CORPUS_PATH):
        print(f"‚ùå Error: No se encuentra la carpeta '{CORPUS_PATH}'")
        print("\nüìù Instrucciones:")
        print("1. Aseg√∫rate de haber descomprimido el archivo DiscursosOriginales.rar")
        print("2. La carpeta debe estar en el mismo directorio que este script")
        print("3. Verifica que la carpeta contenga archivos .txt")
        return 1
    
    try:
        processor = CorpusProcessor(CORPUS_PATH)
        
        processor.process_corpus()
        
        processor.validate_collection()
        
        processor.create_indexes()

        processor.close()
        
        print("\n‚úÖ ¬°Procesamiento completado exitosamente!")
        print("üìù Revisa el archivo 'procesamiento_requisito2.log' para m√°s detalles")
        
        return 0
        
    except KeyboardInterrupt:
        print("\n\n‚ö†Ô∏è  Procesamiento interrumpido por el usuario")
        return 1
        
    except Exception as e:
        print(f"\n‚ùå Error fatal: {e}")
        logger.exception("Error no manejado durante el procesamiento")
        return 1


if __name__ == "__main__":
    exit(main())